{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Machine Learning section.\n",
    "\n",
    ">We will proceed like we did with labels `relevance` but with `positivity`.\n",
    "\n",
    ">We only have 1,420 datapoints, so we will drop the missing values (inputting to the mean introduces bias, as we described before).\n",
    "\n",
    ">`positivity` ranges from `2` to `9`, and this time we will use `sklearn.multiclass.OneVsRestClassifier`.\n",
    "\n",
    "> This strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import nlp_ml_functions\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import label_binarize, MultiLabelBinarizer, binarize, FunctionTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `positivity` as labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "economic_df = pd.read_csv('Full-Economic-News-DFE-839861.csv', encoding='utf-8')\n",
    "new_column_names = ['unit_id', 'golden', 'unit_state', 'trusted_judgments', 'last_judgment_at','positivity', 'positivity_confidence', 'relevance', 'relevance_confidence', 'article_id', 'article_date', 'article_headline', 'positivity_gold', 'relevance_gold', 'article_text']\n",
    "economic_df.columns = new_column_names\n",
    "economic_df = economic_df[np.isfinite(economic_df['positivity'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    343\n",
       "7.0    295\n",
       "4.0    255\n",
       "6.0    214\n",
       "5.0    205\n",
       "8.0     71\n",
       "2.0     35\n",
       "9.0      2\n",
       "Name: positivity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economic_df.positivity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the labels are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    24.154930\n",
       "7.0    20.774648\n",
       "4.0    17.957746\n",
       "6.0    15.070423\n",
       "5.0    14.436620\n",
       "8.0     5.000000\n",
       "2.0     2.464789\n",
       "9.0     0.140845\n",
       "Name: positivity, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economic_df.positivity.value_counts()*100/len(economic_df.positivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting variables `unit_state` and `golden` to numerical values. Dropping columns `positivity_gold` and `relevance_gold` are empty, we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "economic_df['unit_state'] = economic_df['unit_state'].apply(lambda x: 1 if x == 'finalized' else 0)\n",
    "economic_df['golden'] = economic_df['golden'].apply(lambda x: 0 if x == False else 1)\n",
    "del economic_df['positivity_gold']\n",
    "del economic_df['relevance_gold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "economic_df['article_text'] = economic_df['article_text'].apply(nlp_ml_functions.clean_up_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Creating models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_article = economic_df['article_text']\n",
    "y_article = economic_df['positivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_article, X_test_article, y_train_article, y_test_article = train_test_split(X_article, y_article, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 24.41%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  3  1  1  3  1  0  0]\n",
      " [ 0 41 15  7 11 22  2  0]\n",
      " [ 0 24 18 11 10 12  2  0]\n",
      " [ 0 31 10  9 10 14  1  0]\n",
      " [ 0 18 10  7  5 16  0  0]\n",
      " [ 0 18 16  8 15 31  0  0]\n",
      " [ 0  6  4  4  2  5  0  0]\n",
      " [ 0  0  0  0  0  2  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.29      0.42      0.34        98\n",
      "        4.0       0.24      0.23      0.24        77\n",
      "        5.0       0.19      0.12      0.15        75\n",
      "        6.0       0.09      0.09      0.09        56\n",
      "        7.0       0.30      0.35      0.32        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.22      0.24      0.23       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### k-nearest neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('classifier', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 16.20%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  3  0  2  1  2  1  0]\n",
      " [ 0 26  5 37  7 23  0  0]\n",
      " [ 1 29  3 13  6 25  0  0]\n",
      " [ 1 27  4 20  5 17  1  0]\n",
      " [ 0 10  1 21  1 23  0  0]\n",
      " [ 1 27  7 27  5 19  2  0]\n",
      " [ 0  5  0  8  1  7  0  0]\n",
      " [ 0  0  1  0  0  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.20      0.27      0.23        98\n",
      "        4.0       0.14      0.04      0.06        77\n",
      "        5.0       0.16      0.27      0.20        75\n",
      "        6.0       0.04      0.02      0.02        56\n",
      "        7.0       0.16      0.22      0.19        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.14      0.16      0.14       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes Multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('classifier', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...None, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 25.35%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  8  0  0  1  0  0  0]\n",
      " [ 0 71  9  0  4 14  0  0]\n",
      " [ 0 59  8  0  2  8  0  0]\n",
      " [ 0 47  9  0  4 15  0  0]\n",
      " [ 0 39  5  0  2 10  0  0]\n",
      " [ 0 46  5  1  9 27  0  0]\n",
      " [ 0 12  2  0  1  6  0  0]\n",
      " [ 0  2  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.25      0.72      0.37        98\n",
      "        4.0       0.21      0.10      0.14        77\n",
      "        5.0       0.00      0.00      0.00        75\n",
      "        6.0       0.09      0.04      0.05        56\n",
      "        7.0       0.34      0.31      0.32        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.18      0.25      0.18       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes Bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('classifier', BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...lary=None)), ('classifier', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 24.41%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  9  0  0  0  0  0  0]\n",
      " [ 0 91  0  0  0  7  0  0]\n",
      " [ 0 70  1  0  0  6  0  0]\n",
      " [ 0 66  0  0  0  9  0  0]\n",
      " [ 0 48  0  0  0  8  0  0]\n",
      " [ 0 75  0  0  1 12  0  0]\n",
      " [ 0 18  0  0  0  3  0  0]\n",
      " [ 0  2  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.24      0.93      0.38        98\n",
      "        4.0       1.00      0.01      0.03        77\n",
      "        5.0       0.00      0.00      0.00        75\n",
      "        6.0       0.00      0.00      0.00        56\n",
      "        7.0       0.27      0.14      0.18        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.29      0.24      0.13       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 22.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  4  1  1  2  1  0  0]\n",
      " [ 0 58 13  5  4 17  1  0]\n",
      " [ 0 49  6  7  4 11  0  0]\n",
      " [ 0 36  8  2 10 19  0  0]\n",
      " [ 0 25 10  1  8 12  0  0]\n",
      " [ 0 39 16  6  7 20  0  0]\n",
      " [ 0  6  2  1  1 11  0  0]\n",
      " [ 0  1  0  0  1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.27      0.59      0.37        98\n",
      "        4.0       0.11      0.08      0.09        77\n",
      "        5.0       0.09      0.03      0.04        75\n",
      "        6.0       0.22      0.14      0.17        56\n",
      "        7.0       0.22      0.23      0.22        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.17      0.22      0.18       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('classifier', AdaBoostClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...m='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 21.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  5  0  1  0  1  2  0]\n",
      " [ 0 57  5  3  9 22  2  0]\n",
      " [ 0 52  5  2  2 15  1  0]\n",
      " [ 1 47  6  5  4 11  1  0]\n",
      " [ 0 28  3  1  4 17  3  0]\n",
      " [ 0 47  8  4  6 22  1  0]\n",
      " [ 0 14  2  2  0  3  0  0]\n",
      " [ 0  1  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.23      0.58      0.33        98\n",
      "        4.0       0.17      0.06      0.09        77\n",
      "        5.0       0.28      0.07      0.11        75\n",
      "        6.0       0.16      0.07      0.10        56\n",
      "        7.0       0.24      0.25      0.25        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.20      0.22      0.17       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
    "\n",
    "http://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('to_dense',FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),('classifier', GradientBoostingClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 22.77%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  6  0  1  1  1  0  0]\n",
      " [ 0 49 13  3  4 28  1  0]\n",
      " [ 0 40  6  6  3 22  0  0]\n",
      " [ 0 29 12  6  3 23  2  0]\n",
      " [ 0 22  6  2  4 22  0  0]\n",
      " [ 1 29  9  7 10 32  0  0]\n",
      " [ 0  6  2  1  2 10  0  0]\n",
      " [ 0  1  1  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.27      0.50      0.35        98\n",
      "        4.0       0.12      0.08      0.10        77\n",
      "        5.0       0.23      0.08      0.12        75\n",
      "        6.0       0.15      0.07      0.10        56\n",
      "        7.0       0.23      0.36      0.28        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.19      0.23      0.19       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=nlp_ml_functions.process_dataframe_text)),('classifier', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(steps=[('bow', CountVectorizer(analyzer=<function process_dataframe_text at 0x11462e9d8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preproce...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(pipeline.fit(X_train_article, y_train_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:\n",
      " 23.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy:\\n {:.2%}\".format(pipeline.score(X_test_article, y_test_article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      " [[ 0  9  0  0  0  0  0  0]\n",
      " [ 0 98  0  0  0  0  0  0]\n",
      " [ 0 77  0  0  0  0  0  0]\n",
      " [ 0 75  0  0  0  0  0  0]\n",
      " [ 0 56  0  0  0  0  0  0]\n",
      " [ 0 88  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\\n\", confusion_matrix(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "        3.0       0.23      1.00      0.37        98\n",
      "        4.0       0.00      0.00      0.00        77\n",
      "        5.0       0.00      0.00      0.00        75\n",
      "        6.0       0.00      0.00      0.00        56\n",
      "        7.0       0.00      0.00      0.00        88\n",
      "        8.0       0.00      0.00      0.00        21\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.05      0.23      0.09       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/nlp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n\\n\", classification_report(y_test_article, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [nlp]",
   "language": "python",
   "name": "Python [nlp]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
